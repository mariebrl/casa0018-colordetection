{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dj2f4hAh_ZNe"
   },
   "source": [
    "# Model for color detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6o1Hy4V_Wff"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXxNGEWA_U3a",
    "outputId": "2ed47ed8-4ae5-4c18-adce-a757697fa7d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:45:29.283814: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay, recall_score, classification_report\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "seed = 157 # fix randomisation\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgB8tBz095pl",
    "outputId": "befcb88f-75fa-4d2a-8996-3745e957a3e4"
   },
   "outputs": [],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQGVJ1RGCO87"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAx4_wPT_kir"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UV5cHyMj_VaB"
   },
   "outputs": [],
   "source": [
    "# color_set = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/UCL/Assessment/color_dataset.csv')\n",
    "color_set = pd.read_csv('/Users/mariebourel/Documents/Fac/Master 2022_2023/UCL/cours/CASA0018 - Deep Learning for sensor network /Coursework/color_dataset.csv')\n",
    "color_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs73LdNC_pFV"
   },
   "source": [
    "## Data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yziEOlvp_VkF",
    "outputId": "8a8979d1-6f83-4911-e192-aedce42ebf60"
   },
   "outputs": [],
   "source": [
    "color_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wAzhs0lG_VtU",
    "outputId": "b4cc27bd-a861-45e0-d22d-8677e52e1e74"
   },
   "outputs": [],
   "source": [
    "color_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4iNJlfd_WC8",
    "outputId": "64b2ca27-09d1-4d0d-8695-74b2e94d8bd9"
   },
   "outputs": [],
   "source": [
    "color_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kwVVpk1_wbV"
   },
   "outputs": [],
   "source": [
    "nb_col=len(color_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtkDUDRh_yJy"
   },
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsI257xG_0kN"
   },
   "source": [
    "### Data Encoding\n",
    "Converting the label into binary variables using One-Hot Encoding as there is no order in the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "1eFYPPA-_wYP",
    "outputId": "153f7cc7-73cb-421e-b3a3-49d8a7b4c21c"
   },
   "outputs": [],
   "source": [
    "df_colors = pd.get_dummies(color_set, columns=['label'])\n",
    "df_colors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z4P1dVe5kHQ"
   },
   "source": [
    "### Data Normalization\n",
    "Transform the RGB value from 0 to 255 to values from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YB4UpU0d5kUQ"
   },
   "outputs": [],
   "source": [
    "df_colors['red'] = df_colors['red'] / 255.0\n",
    "df_colors['green'] = df_colors['green'] / 255.0\n",
    "df_colors['blue'] = df_colors['blue'] / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "pzZFIdbt_HyS",
    "outputId": "31fe6a0f-16c5-460e-fe63-840461055091"
   },
   "outputs": [],
   "source": [
    "df_colors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to summarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df_data):\n",
    "    # normalization input\n",
    "    df_data['red'] = df_data['red'] / 255.0\n",
    "    df_data['green'] = df_data['green'] / 255.0\n",
    "    df_data['blue'] = df_data['blue'] / 255.0\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raW5gRHB_4Q7"
   },
   "source": [
    "### Split the dataset (70/15/15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lMYoy3J_6em"
   },
   "source": [
    "Splitting the dataset into 2 sets:\n",
    "  - 85% for the training set (used to get the parameters of the model) including 15% for validation set (used to define the hyperparameter and avoid overfitting)\n",
    "  - 15% for test set (used to test the model on unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNhxRJfD_wUm"
   },
   "outputs": [],
   "source": [
    "# sample the dataset\n",
    "df = shuffle(df_colors)\n",
    "\n",
    "# split between xs an ys\n",
    "xs, ys = np.split(df.values, [3], axis=1)\n",
    "#ys = ys.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-uosgmK_wOE"
   },
   "outputs": [],
   "source": [
    "xs_train, xs_test, ys_train, ys_test = train_test_split(xs, ys, test_size = 0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJdnsOw5sPdf"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxA6pGSDxeim"
   },
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9LUhKp92c1Y"
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNGun4Gcxfqc"
   },
   "source": [
    "Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UuB7Xq3xlPe",
    "outputId": "d1f6cebd-1cff-4061-bfc2-4dd8932b9ef6"
   },
   "outputs": [],
   "source": [
    "# Parameters model 1\n",
    "nb_layers1 = 2\n",
    "activation_fct = 'relu'\n",
    "loss_function = 'mean_squared_error'\n",
    "optimizer = 'adam'\n",
    "xs_shape = len(pd.DataFrame(xs_train).keys())\n",
    "\n",
    "# model 1\n",
    "model1 = keras.Sequential([\n",
    "    layers.Dense(3, input_shape=[xs_shape], activation=activation_fct),\n",
    "    layers.Dense(16, activation = activation_fct),\n",
    "    layers.Dense(11)\n",
    "])\n",
    "model1.summary()\n",
    "\n",
    "# compile the model 1\n",
    "model1.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYxrUA2l2xP6"
   },
   "source": [
    "Train the model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONOwWOgzzMMh",
    "outputId": "8cd7ed4a-8ba7-4804-b81a-6108e4272e23"
   },
   "outputs": [],
   "source": [
    "# fit the model with the Train set\n",
    "training_history1 = model1.fit(x=xs_train, y=ys_train, \n",
    "                               validation_split=0.15, epochs=200,\n",
    "                               batch_size=100)\n",
    "\n",
    "# best accuracy 0.4671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "joPsLQSe__hw",
    "outputId": "a9e2a98c-8c53-4b6c-a591-80e013ffadd0"
   },
   "outputs": [],
   "source": [
    "hist1 = pd.DataFrame(training_history1.history)\n",
    "hist1['epoch'] = training_history1.epoch\n",
    "hist1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezntEzqBBnV3",
    "outputId": "83b30a72-b29f-4ded-d79f-65f0069c1704"
   },
   "outputs": [],
   "source": [
    "# Accuracy on training sets\n",
    "accuracy_m1_train = model1.evaluate(xs_train, ys_train) # loss: 0.0329 - accuracy: 0.7606\n",
    "\n",
    "print('Accuracy on train set', accuracy_m1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "niEqwWLIHGhI",
    "outputId": "a8a7dd05-a05d-4ee8-ca71-cefb04193b59"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist1['accuracy'])\n",
    "plt.plot(hist1['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozf3iJrL3UtM"
   },
   "source": [
    "Evaluate and predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hFCbr3c0RdA",
    "outputId": "26432192-6354-4b6d-cf99-4cf3216a90d9"
   },
   "outputs": [],
   "source": [
    "model1_test_predict = model1.evaluate(xs_test, ys_test) # loss: 0.0294 - accuracy: 0.7814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2DBEX613Zqo",
    "outputId": "012e267d-a865-47b8-acf6-6f74bac610d3"
   },
   "outputs": [],
   "source": [
    "test_prediction1 = model1.predict(xs_test)\n",
    "print(\"shape is {}\".format(test_prediction1.shape))  \n",
    "test_prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G27SvPA5_RF2",
    "outputId": "6b498ff0-3acd-48a8-9f10-adde7bf5c6e8"
   },
   "outputs": [],
   "source": [
    "color_class1 = model1.predict(xs_test)\n",
    "\n",
    "print(color_class1[8])\n",
    "print(ys_test[8]) # color 2 ie blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTAQIHTG2rbP"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gvl04Ftc2qg5"
   },
   "source": [
    "Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1ZUBUkusxxm",
    "outputId": "30141a95-76e2-4317-8e9a-bda63baebe2c"
   },
   "outputs": [],
   "source": [
    "# Parameters model 2\n",
    "activation_fct = 'relu'\n",
    "loss_function = 'mean_squared_error'\n",
    "optimizer = 'adam'\n",
    "\n",
    "# model 2\n",
    "model2 = keras.Sequential([\n",
    "    layers.Dense(3, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct, input_shape=[3]),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(11)\n",
    "  ])\n",
    "model2.summary()\n",
    "\n",
    "# compile the model 2\n",
    "model2.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQoXHeI3scOs"
   },
   "source": [
    "Train the model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0z1pBBWsZTZ",
    "outputId": "5c8c9914-416b-445a-ef2d-28ce8e674073"
   },
   "outputs": [],
   "source": [
    "training_history2 = model2.fit(x=xs_train, y=ys_train, \n",
    "                               validation_split=0.15, epochs=200, \n",
    "                               batch_size=100, verbose=1,\n",
    "                               #callbacks=[tfdocs.modeling.EpochDots()], \n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hK5z1ZBrAL8C",
    "outputId": "a932f9b9-afca-47d1-807b-33658a1b75ea"
   },
   "outputs": [],
   "source": [
    "hist2 = pd.DataFrame(training_history2.history)\n",
    "hist2['epoch'] = training_history2.epoch\n",
    "hist2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpoxXewv897s",
    "outputId": "ca242f94-98ac-4a2a-bfd2-a748ad3d9236"
   },
   "outputs": [],
   "source": [
    "# Accuracy on training sets\n",
    "accuracy_m2_train = model2.evaluate(xs_train, ys_train) # loss: 0.0420 - accuracy: 0.7585\n",
    "\n",
    "print('Accuracy on train set', accuracy_m2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "5au20iE8HCPL",
    "outputId": "838d9b1d-72fb-4b2f-ef56-86c2448e69e7"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist2['accuracy'])\n",
    "plt.plot(hist2['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3iGFD8A4ARp"
   },
   "source": [
    "Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0e3Nk_G1Kkw",
    "outputId": "b03029fb-759d-4505-bb8b-5710d4b8f742"
   },
   "outputs": [],
   "source": [
    "model2_test_predict = model2.evaluate(xs_test, ys_test) #  loss: 0.0430 - accuracy: 0.7349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0jQBx1T4ARq",
    "outputId": "b22879db-3b75-4c02-eec6-3af0bdcb625b"
   },
   "outputs": [],
   "source": [
    "test_prediction2 = model2.predict(xs_test)\n",
    "print(\"shape is {}\".format(test_prediction2.shape))  \n",
    "test_prediction2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ec8E9OGz1K3m"
   },
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcR3sti71K3m"
   },
   "source": [
    "Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErNCgGVF1K3m",
    "outputId": "ebb16b3c-1290-41c6-f0fc-ba0ab0a1a1d0"
   },
   "outputs": [],
   "source": [
    "# Parameters model 3\n",
    "activation_fct = 'relu'\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model 3\n",
    "model3 = keras.Sequential([\n",
    "    layers.Dense(3, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct, input_shape=(3,)),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(11)\n",
    "  ])\n",
    "model3.summary()\n",
    "\n",
    "# compile the model 3\n",
    "model3.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUohXqd61-td",
    "outputId": "5ecd545d-b492-4793-fbd7-a9d82cc109ce"
   },
   "outputs": [],
   "source": [
    "training_history3 = model3.fit(x=xs_train, y=ys_train, \n",
    "                               validation_split=0.15, epochs=200, \n",
    "                               batch_size=200, verbose=1,\n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XJqhOiQ68FhN",
    "outputId": "dcb9799b-99e0-4483-b69d-dc54f489a9fc"
   },
   "outputs": [],
   "source": [
    "hist3 = pd.DataFrame(training_history3.history)\n",
    "hist3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXyov14n9FRO",
    "outputId": "07066f9d-45ad-480d-9cdf-6bc50626f1da"
   },
   "outputs": [],
   "source": [
    "# Accuracy on training sets\n",
    "accuracy_m3_train = model3.evaluate(xs_train, ys_train) # loss: 0.5169 - accuracy: 0.8095\n",
    "\n",
    "print('Accuracy on train set', accuracy_m3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "glgRbdhOG4um",
    "outputId": "5a31676d-23f8-45c1-ac3a-3b6a40563744"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.plot(hist3['accuracy'])\n",
    "plt.plot(hist3['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "SdZb3xbwHBEX",
    "outputId": "13faf3b5-7ac0-48a1-c794-67a717954fc2"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "plt.plot(training_history3.history['loss'], label='Train')\n",
    "plt.plot(training_history3.history['val_loss'], label='Validation')\n",
    "plt.ylabel('Binary Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ3aUUqE4BKT"
   },
   "source": [
    "Evaluate and predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VR39ZF_M4Gf1",
    "outputId": "33c97efd-819e-4ad8-c49e-525b8866a13b"
   },
   "outputs": [],
   "source": [
    "model3_test_predict = model3.evaluate(xs_test, ys_test) # loss: 0.4480 - accuracy: 0.8546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e595hJe4BKT",
    "outputId": "9daca7a6-c981-4689-c7ce-3aeb0f2b5f4a"
   },
   "outputs": [],
   "source": [
    "test_prediction3 = model3.predict(xs_test)\n",
    "print(\"shape is {}\".format(test_prediction3.shape))  \n",
    "test_prediction3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzZzDd5dm3x7"
   },
   "source": [
    "#### Model 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l__Z942vm3x7"
   },
   "source": [
    "Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sV6gB3RY4ArN",
    "outputId": "2cd1f4c3-aa37-454b-a315-86ae8f72abe4"
   },
   "outputs": [],
   "source": [
    "# Parameters model 4\n",
    "activation_fct = 'relu'\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model 4\n",
    "model4 = keras.Sequential([\n",
    "    layers.Dense(3, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct, input_shape=(3,)),\n",
    "    layers.Dense(30, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(11)\n",
    "  ])\n",
    "model4.summary()\n",
    "\n",
    "# compile the model \n",
    "model4.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKM3EAPIEz1H",
    "outputId": "99bdbaa0-cf50-4c57-bdfb-7e491dc86746"
   },
   "outputs": [],
   "source": [
    "training_history4 = model4.fit(x=xs_train, y=ys_train, \n",
    "                               validation_split=0.15, epochs=200, \n",
    "                               batch_size=200, verbose=1,\n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1cN0w2msFWEA",
    "outputId": "c9b9f10b-9528-4e75-b8de-63470c6940e1"
   },
   "outputs": [],
   "source": [
    "hist4 = pd.DataFrame(training_history4.history)\n",
    "hist4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1Re7UMW9NDK",
    "outputId": "35f4a25f-ace2-465b-e9dc-a02adfadfbd2"
   },
   "outputs": [],
   "source": [
    "# Accuracy on training sets\n",
    "accuracy_m4_train = model4.evaluate(xs_train, ys_train) # loss: 0.4072 - accuracy: 0.8765\n",
    "\n",
    "print('Accuracy on train set', accuracy_m4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "yYQfTF65GgGE",
    "outputId": "934453b7-36d2-4e9c-cc19-33dcda236759"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist4['accuracy'])\n",
    "plt.plot(hist4['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXUoJ2c3Ezu4",
    "outputId": "6147e195-00c5-473f-81f8-a3c7320921e2"
   },
   "outputs": [],
   "source": [
    "model4_test_predict = model4.evaluate(xs_test, ys_test) # loss: 0.4553 - accuracy: 0.8566"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSILVr4-m71s"
   },
   "source": [
    "#### Model 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5kPvZpCm71t"
   },
   "source": [
    "Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7Wz5cXgL_I8"
   },
   "outputs": [],
   "source": [
    "def create_model(activation='relu'):\n",
    "  # create model\n",
    "  model5 = keras.Sequential([\n",
    "    layers.Dense(3, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(3,)),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='Softmax'),\n",
    "    layers.Dense(11)\n",
    "  ])\n",
    "  # Compile model\n",
    "  model5.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                 optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "  return model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bag09UEtmwXf",
    "outputId": "440978c8-1024-4352-beb6-5eb589e5f26c"
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "activation_fct = ['softmax', 'relu']\n",
    "#activation_fct = ['tanh', 'hard_sigmoid', 'linear', 'sigmoid']\n",
    "param_grid = dict(optimizer__learning_rate=learn_rate, optimizer__momentum=momentum, model__activation=activation_fct)\n",
    "\n",
    "# other parameters\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model 5\n",
    "# create model\n",
    "model5 = KerasClassifier(model=create_model, epochs=150, batch_size=200, verbose=0)\n",
    "\n",
    "grid_result5 = GridSearchCV(estimator=model5, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "grid_result5.fit(xs_train, ys_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zURRpodLLcrO"
   },
   "outputs": [],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid_result5.best_params_)\n",
    "best_param5 = grid_result5.best_params_\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid_result5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vJD8c35Lcmh"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_model5_train = grid_result5.score(xs_train, ys_train)\n",
    "model5_test_predict = grid_result5.score(xs_test, ys_test)\n",
    "\n",
    "print('Accuracy of model (train)', accuracy_model5_train)\n",
    "print('Accuracy of model (test)', model5_test_predict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtOxFMgsHp5a"
   },
   "source": [
    "#### Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3iZxoWBHpGm"
   },
   "source": [
    "Based on the model 3 parameters, this section will be used to adjust the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxX6f9DDHoup"
   },
   "outputs": [],
   "source": [
    "# Parameters model 6\n",
    "activation_fct = 'relu'\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "# model 6\n",
    "model6 = keras.Sequential([\n",
    "    layers.Dense(3, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct, input_shape=(3,)),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(11)\n",
    "  ])\n",
    "model6.summary()\n",
    "\n",
    "# compile the model 6\n",
    "model6.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4L8V53nSVUA"
   },
   "outputs": [],
   "source": [
    "# Fit on training set\n",
    "training_history6 = model6.fit(x=xs_train, y=ys_train, \n",
    "                               validation_split=0.15, epochs=275, \n",
    "                               batch_size=300, verbose=0,\n",
    "                               shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjC5RbT49aQP"
   },
   "outputs": [],
   "source": [
    "# Accuracy on training sets\n",
    "accuracy_m6_train = model6.evaluate(xs_train, ys_train) # loss: 0.5171 - accuracy: 0.8288\n",
    "\n",
    "print('Accuracy on train set', accuracy_m6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8s_dWFDrMz7K"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.plot(training_history6.history['accuracy'], label='Train')\n",
    "plt.plot(training_history6.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Accuracy', pad=13)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0v-ashEINwd"
   },
   "outputs": [],
   "source": [
    "plt.plot(training_history6.history['loss'], label='Train')\n",
    "plt.plot(training_history6.history['val_loss'], label='Validation')\n",
    "plt.ylabel('Binary Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm6-sMYiIfWx"
   },
   "outputs": [],
   "source": [
    "model6_test_predict = model6.evaluate(xs_test, ys_test) # loss: 0.5570 - accuracy: 0.8121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TnTxmUCWEyp"
   },
   "source": [
    "#### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNC9OJs1Ws7q"
   },
   "outputs": [],
   "source": [
    "# Parameters model 7\n",
    "activation_fct = 'relu'\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "# model 7\n",
    "model7 = keras.Sequential([\n",
    "    layers.Dense(3, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct, input_shape=(3,)),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(24, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=activation_fct),\n",
    "    layers.Dense(11)\n",
    "  ])\n",
    "model7.summary()\n",
    "\n",
    "# compile the model 6\n",
    "model7.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwTaxHmpXkTI"
   },
   "outputs": [],
   "source": [
    "# Fit on training set\n",
    "training_history7 = model7.fit(x=xs_train, y=ys_train, \n",
    "                               validation_split=0.15, epochs=300, \n",
    "                               batch_size=315, verbose=0,\n",
    "                               shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJrYOrUT9lai"
   },
   "outputs": [],
   "source": [
    "# Accuracy on training sets\n",
    "accuracy_m7_train = model7.evaluate(xs_train, ys_train) # loss: loss: 0.5633 - accuracy: 0.8052\n",
    "print('Accuracy on train set', accuracy_m7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DSl8PgJXtdS"
   },
   "outputs": [],
   "source": [
    "plt.plot(training_history7.history['loss'], label='Train')\n",
    "plt.plot(training_history7.history['val_loss'], label='Validation')\n",
    "plt.ylabel('Binary Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nVtTPymXwjM"
   },
   "outputs": [],
   "source": [
    "model7_test_predict = model7.evaluate(xs_test, ys_test) # loss: 0.5914 - accuracy: 0.7943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp-Zyh4hPHF6"
   },
   "source": [
    "## Compare Accuray of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nbix_R3vPGiM"
   },
   "outputs": [],
   "source": [
    "df_accuracy = pd.DataFrame([model1_test_predict, model2_test_predict, model3_test_predict, model4_test_predict, [0, model5_test_predict], model6_test_predict, model7_test_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7z_7D_Y6PGfW"
   },
   "outputs": [],
   "source": [
    "df_accuracy = df_accuracy.rename({0: 'loss', 1: 'accuracy'}, axis=1)\n",
    "df_accuracy[\"model\"] = [\"model1\", \"model2\", \"model3\", \"model4\", \"model5\", \"model6\", \"model7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcGDHGo_QGfO"
   },
   "outputs": [],
   "source": [
    "df_accuracy.sort_values('accuracy') #  => best model is model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_EhMn60A4HP"
   },
   "source": [
    "#### Evaluate performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAkTLQnzDuSK"
   },
   "outputs": [],
   "source": [
    "model4_predictions = model4.predict(xs_test)\n",
    "model4_predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results into labelled colors\n",
    "dict_colors = {}\n",
    "\n",
    "for ind, val in enumerate(list(df_colors.columns.values)[3:]):\n",
    "    dict_colors[ind] = val\n",
    "\n",
    "print(dict_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tocolor(predictions):\n",
    "    pred_max = np.argmax(predictions, axis=1)\n",
    "    labelled_colors_pred = []\n",
    "    for i in list(pred_max):\n",
    "        labelled_colors_pred.append(dict_colors[i])\n",
    "    return labelled_colors_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_pred = convert_tocolor(model4_predictions)\n",
    "colors_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kYbAveDA2dF"
   },
   "outputs": [],
   "source": [
    "target_names = ['Black', 'Blue', 'Brown', 'Green', 'Grey', 'Orange', 'Pink', 'Purple', 'Red', 'White', 'Yellow']\n",
    "model4_predictions = np.argmax(model4_predictions, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_mat = confusion_matrix(ys_test_list, model4_predictions)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_mat, display_labels = target_names)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# model performance report\n",
    "print(classification_report(ys_test_list, model4_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW_ICqnimajY"
   },
   "source": [
    "Test with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qwdNh9MSMKX"
   },
   "outputs": [],
   "source": [
    "xs_test_other = np.array([[250/255, 104/255, 0], [170, 0, 255/255]])\n",
    "\n",
    "convert_tocolor(model4.predict(xs_test_other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io2z3PMhwdJd"
   },
   "source": [
    "## Towards Arduino\n",
    "\n",
    "ref: https://colab.research.google.com/github/arduino/ArduinoTensorFlowLiteTutorials/blob/master/GestureToEmoji/arduino_tinyml_workshop.ipynb#scrollTo=0Xn1-Rn9Cp_8\n",
    "\n",
    "https://colab.research.google.com/github/ucl-casa-ce/casa0018/blob/main/Week4/CASA0018_4_1_train_hello_world_model.ipynb#scrollTo=1muAoUm8lSXL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JAEfLx9QT5i"
   },
   "source": [
    "### Convert the Trained Model n° 4 to Tensor Flow Lite\n",
    "In the below cell, we convert the model *4* format into TFlite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0a-YGgTwD-Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CENRlGhkhSBF"
   },
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model4.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxvytx8dV4lk",
    "outputId": "dfb9785a-dc41-4109-eaa9-7bcca6538c0b"
   },
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(tflite_model)\n",
    "\n",
    "# Define a generator function that provides our test data's x values as a representative dataset, and tell the converter to use it\n",
    "def representative_dataset_generator():\n",
    "  for value in xs_train:\n",
    "    # Each scalar value must be inside of a 2D array that is wrapped in a list\n",
    "    yield [np.array(value/255, dtype=np.float32, ndmin=3)]\n",
    "\n",
    "# Indicate that we want to perform the default optimizations, which include quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.representative_dataset = representative_dataset_generator\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ntJfIXCwUPJ",
    "outputId": "999c508a-325d-4216-d870-6dd44402faaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset_generator():\n",
    "  for value in xs_train:\n",
    "    liste = value/255\n",
    "    yield [np.array(liste, dtype=np.float32, ndmin=3)]\n",
    "\n",
    "# Set the optimization flag - DEFAULT includes quantization.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Enforce integer only quantization to reduce model size\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset_generator\n",
    "\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aw-WvOgAQUGy"
   },
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model4)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"colourdetec_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "\n",
    "basic_model_size = os.path.getsize(\"colourdetec_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hrpt8qWdGiPT"
   },
   "source": [
    "### Convert the Trained Model n° 4 to be used in Arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrFdblQOGijn",
    "outputId": "4c4cc786-2b7a-4384-833b-5b5aaf676fd3"
   },
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > /content/model_colour.h\n",
    "!cat MODEL_TFLITE | xxd -i      >> /content/model_colour.h\n",
    "!echo \"};\"                              >> /content/model_colour.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"model_colour.h\")\n",
    "print(f\"Header file, model_colour.h, is {model_h_size:,} bytes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtNkdyRaw29A"
   },
   "source": [
    "#### Compare performance after conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVWOjniaw3rp"
   },
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, x_test):\n",
    "  # Prepare the test data\n",
    "  x_test_ = x_test.copy()\n",
    "  #x_test_ = x_test_.reshape((x_test.size, 1))\n",
    "  x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  # If required, quantize the input layer (from float to integer)\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  if (input_scale, input_zero_point) != (0.0, 0):\n",
    "    x_test_ = x_test_ / input_scale + input_zero_point\n",
    "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "  \n",
    "  # Invoke the interpreter\n",
    "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
    "  for i in range(len(x_test_)):\n",
    "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "    interpreter.invoke()\n",
    "    y_pred[i] = np.argmax(interpreter.get_tensor(output_details[\"index\"])[[0]])\n",
    "  \n",
    "  # If required, dequantized the output layer (from integer to float)\n",
    "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "  if (output_scale, output_zero_point) != (0.0, 0):\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    y_pred = (y_pred - output_zero_point) * output_scale\n",
    "\n",
    "  return y_pred\n",
    "\n",
    "def evaluate_tflite(tflite_model, x_test, y_true):\n",
    "  global model4\n",
    "  y_pred = predict_tflite(tflite_model, x_test)\n",
    "  loss_function = tf.keras.losses.get(model4.loss)\n",
    "  loss = loss_function(y_true, y_pred).numpy()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_WER0TAxFQH"
   },
   "outputs": [],
   "source": [
    "# Calculate predictions\n",
    "y_test_pred_tf = model4.predict(xs_test)\n",
    "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, xs_test)\n",
    "y_test_pred_tflite = predict_tflite(model_tflite, xs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wki-O4YJ1hin"
   },
   "source": [
    "### Generate a TensorFlow Lite for Microcontrollers Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roKLbYwe1h6A"
   },
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey7NGm852Leb"
   },
   "outputs": [],
   "source": [
    "MODEL_TFLITE_MICRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEV5KE0u2J67"
   },
   "outputs": [],
   "source": [
    "# Print the C source file\n",
    "!cat {MODEL_TFLITE_MICRO}\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "P9LUhKp92c1Y",
    "RTAQIHTG2rbP",
    "Ec8E9OGz1K3m",
    "sSILVr4-m71s",
    "VtOxFMgsHp5a",
    "6TnTxmUCWEyp"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tinyml",
   "language": "python",
   "name": "tinyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
